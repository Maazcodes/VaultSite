# Vault Site

Vault digital preservation service.

<!-- note: Table of contents below is autogenerated by markdown-toc -->

<!-- toc -->

- [Development](#development)
  * [Docker-Dev Install](#docker-dev-install)
  * [Virtualenv + Docker Install](#virtualenv--docker-install)
- [Dependency Management](#dependency-management)
  * [Adding new dependencies](#adding-new-dependencies)
- [Deployment](#deployment)
- [Code Quality](#code-quality)
  * [Black -- opinionated formatting](#black----opinionated-formatting)
  * [Pylint -- linting and static analysis](#pylint----linting-and-static-analysis)
  * [Frontend](#frontend)
- [Releases](#releases)
- [Operations](#operations)
  * [Triggers](#triggers)

<!-- tocstop -->

## Development

### Docker-Dev Install

See https://git.archive.org/archive-it/docker-dev#vault-site-development-quick-start

Use Docker-Dev for a quicker setup.

### Virtualenv + Docker Install
- Python 3.8
- If on Apple Silicon: `brew install postgresql` so we can compile psycopg2-binary
    - There currently isn't an arm64 wheel for psycopg2-binary
    - We won't run this brew install of postgres, it will run in a container
    - You may first need to `brew install openssl readline sqlite3 xz zlib`
- Run Postgres, install into virtual environment, and start the app:
```
cd path/to/project
vault/utilities/dev-postgres.sh start
make setup
# set up git pre-commit hook; optional, but recommended
make .git/hooks/pre-commit
make migrate
AIT_CONF=./DPS_dev/vault.yml ./venv/bin/python manage.py createsuperuser
make run
# in a separate shell:
make test
```

**Finally**
- Log in to [admin](http://localhost:8000/admin/)
- Create a plan, an organization and associate your user with that org
- From the [dashboard](http://localhost:8000/dashboard), create a collection
- Deposit file(s) to your new collection

## Dependency Management
The project is using [pip-tools(https://github.com/jazzband/pip-tools) for
dependency management. To get things running it can be as simple as `pip
install -r requirements.dev.txt` but if you use `pip-sync requirements.dev.txt`
it will keep your virtualenv in sync with the pinned dependencies.

There are three sets of dependencies for three environments:
- requirements.txt (prod/qa/etc)
- requirements.test.txt (all the above plus deps for running tests)
- requirements.dev.txt (all the above plus deps for local development)

You only need to install one set of dependencies for the environment you're
running in. Each of these `.txt` files has a corresponding `.in` file. The
`.txt` files serve as the lock file including pinned versions of all transitive
dependencies.

### Adding new dependencies

- Add the name of the package to the corresponding `.in` file for the
  environment the dependency is appropriate for.
- Run `pip-compile` "inside out" from the environment you added the dep to.
  - E.g. when a dep is added to requirements.in run pip-compile on
    requirements.in, requirements.test.in, then requirements.dev.in
- Run `pip-sync` for the corresponding `.txt` file for the environment

## Deployment
Vault is deployed using
[ait-ansible](https://git.archive.org/archive-it/ait-ansible). Vault is
**always** deployed using the `master` branch of `ait-ansible`, regardless of the
target environment. So that we always understand exactly what changes we're
deploying, deployments must be made targeting a specific git ref (i.e., a hash,
tag, or branch name), which we do using the `git_ref` ansible var. Example:

```sh
# - be ssh'd onto a machine in-cluster
# - have an up-to-date clone of ait-ansible

# from the ait-ansible directory
pwd
./git.archive.org/archive-it/ait-ansible

# git refs are provided via the `git_ref` var
ansible-playbook --ask-vault-password -i qa setup_vault_site.yml --extra-vars git_ref=eec824149cc850e094dd92921e4af0f8f13ee380
# ...
```

## Code Quality
### Black -- opinionated formatting
* `make ck-format` / `make format`
* https://github.com/psf/black

### Pylint -- linting and static analysis
* `make lint`
* https://pylint.org/
* [Pylint message descriptions](https://pycodequ.al/docs/pylint-messages.html)
* [Ignoring issues](https://pycodequ.al/docs/ignore-issues.html)

### Frontend
The vault frontend uses [`eslint`](https://eslint.org/),
[`prettier`](https://prettier.io/) to assert baseline code quality.
[`nvm`](https://github.com/nvm-sh/nvm) is used to make it simpler for all
developers to target the same version of `node`.

```sh
# First, install nvm: https://github.com/nvm-sh/nvm#installing-and-updating
# This must only be done once on a given workstation.

# Next, install the target version of node. The target version is determined by
# the contents of ./.nvmrc. This step is only necessary when first setting up
# vault for development or when the version of node used by vault changes.
nvm install

# Make the yarn package manager for node available. This step is only necessary
# when first setting up vault for development or when the version of node used
# by vault changes.
corepack enable

# Activate the target node version according to ./nvmrc. This step is necessary
# to run in each new shell session.
nvm use

# Be in the frontend JavaScript directory
cd vault/static/js

# Run static analysis checks with eslint:
make lint

# Assert formatting correctness with prettier:
make ck-format

# Modify JavaScript source for formatting compliance:
make format
```

## Releases
Here we describe the process we use to define, deploy, and patch releases.

1. Determine `release-date`, i.e., when the release is planned to ship to prod.
2. Plan a `branch-cut-date` which is **one week** prior to `release-date`.
   Under normal circumstances, all features which are to ship on `release-date`
   must be reviewed and merged to `master` prior to `branch-cut-date`.
3. Create the release branch: on `branch-cut-date`, create a branch
   `releases/YYYY-MM-DD` describing the current date. This branch contains the
   code that will ultimately ship to production.
4. Deploy `releases/YYYY-MM-DD` to the QA environment. Then ask QA users to begin
   testing the software to search for bugs. See the note below about disabling
   continuous delivery during pre-release QA.
5. Bugs discovered on the release branch are addressed as follows:
   1. A branch is created based on `releases/YYYY-MM-DD`, in which the bug is
      fixed.
   2. The bugfix branch is squashed and merged into the release branch.
   3. The resulting commit is **immediately** `cherry-pick`ed onto `master`.
      This ensures that bugfixes on the release branch do not appear in later
      releases as regressions. Cherry-picks which result in conflicts caused by
      diverging `master` and release branches should probably be put through
      code review.
   4. The updated `releases/YYYY-MM-DD` is deployed to the QA environment.
6. On `release-date`, `releases/YYYY-MM-DD` is deployed to production.
7. Bugs of sufficient severity discovered in production are fixed using the
   identical procedure as described above for fixing bugs during pre-release
   QA. Regarding "severity": arguably only blocker bugs should be deployed as
   hotfixes; bugs of lesser severity should be fixed on `master` and deployed
   on the next scheduled production release.

:notebook_with_decorative_cover: **Note**: During pre-release QA it might be
desirable to disable automatic QA deployments via CD in order to keep the QA
environment pinned to the code present on `releases/YYYY-MM-DD`. This can be
accomplished by setting `ENABLE_CD` to `false` in the Gitlab CI variables for
the vault-site project: https://git.archive.org/dps/vault-site/-/settings/ci_cd
. To enable automatic QA deployments, `ENABLE_CD` **must** be set to `true`.

## Operations

### Triggers
`vault` makes heavy use of Postgres triggers. It's handy to be able to view and
enable/disable them.

**View Triggers**

```
# in a psql REPL:
vault=# \d vault_treenode
                                             Table "public.vault_treenode"

# ...

Triggers:
    treenode_file_accounting_delete_trg AFTER DELETE ON vault_treenode FOR EACH ROW WHEN (old.node_type::text = 'FILE'::text OR old.node_type::text = 'FOLDER'::text) EXECUTE PROCEDURE _do_treenode_delete_file_accounting()
    treenode_file_accounting_insert_trg AFTER INSERT ON vault_treenode FOR EACH ROW WHEN (new.node_type::text = 'FILE'::text OR new.node_type::text = 'FOLDER'::text) EXECUTE PROCEDURE _do_treenode_insert_file_accounting()
    treenode_file_accounting_update_trg AFTER UPDATE ON vault_treenode FOR EACH ROW WHEN (new.node_type::text = 'FILE'::text OR new.node_type::text = 'FOLDER'::text) EXECUTE PROCEDURE _do_treenode_update_file_accounting()
    treenode_path_after_trg AFTER UPDATE ON vault_treenode FOR EACH ROW WHEN (new.path IS DISTINCT FROM old.path) EXECUTE PROCEDURE _update_descendants_treenode_path()
    treenode_path_insert_trg BEFORE INSERT ON vault_treenode FOR EACH ROW EXECUTE PROCEDURE _update_treenode_path()
    treenode_path_prevent_null_trg BEFORE UPDATE ON vault_treenode FOR EACH ROW WHEN (new.path IS NULL) EXECUTE PROCEDURE _reject_null_treenode_path()
    treenode_path_update_trg BEFORE UPDATE ON vault_treenode FOR EACH ROW WHEN (old.parent_id IS DISTINCT FROM new.parent_id OR old.id IS DISTINCT FROM new.id) EXECUTE PROCEDURE _update_treenode_path()
    treenode_set_new_file_count BEFORE INSERT ON vault_treenode FOR EACH ROW WHEN (new.node_type::text = 'FILE'::text) EXECUTE PROCEDURE _do_treenode_set_new_file_count()
```
:notebook_with_decorative_cover: **Note**: any disabled triggers will be listed
under a subsection of the display printed above with the title: `Disabled user
triggers`.

**Enable/Disable Triggers**

```
# in a psql REPL:
# to disable:
ALTER TABLE "vault_treenode" DISABLE TRIGGER <trigger-name>;

# to enable:
ALTER TABLE "vault_treenode" ENABLE TRIGGER <trigger-name>;

# also, if necessary, trigger enablement can be programmatically determined:
SELECT tgenabled FROM pg_trigger WHERE tgname = '<trigger-name>';
```
